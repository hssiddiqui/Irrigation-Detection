{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ll3cxjbC2Fk"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "import ee\n",
        "from google.colab import auth\n",
        "import tensorflow as tf\n",
        "import folium\n",
        "from google.cloud import storage\n",
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.signal import savgol_filter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from copy import copy\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "# Install and import rasterio\n",
        "!pip install rasterio==1.3.3\n",
        "import rasterio\n",
        "\n",
        "# Install and import catboost\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE26e4lGanEF"
      },
      "outputs": [],
      "source": [
        "## Authentication cell\n",
        "\n",
        "# Authenticate Google account\n",
        "# auth.authenticate_user()\n",
        "from google.oauth2.service_account import Credentials\n",
        "credentials = Credentials.from_service_account_file('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRK6zoen9VN2"
      },
      "source": [
        "## Accesses S2 imagery to make irrigation predictions\n",
        "#### The following portion of this notebook loads a pretrained model, accesses the S2 imagery uploaded to GCP, processes the imagery, makes predictions, and then uploads the results back to GCP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpGnn-Rwj14g"
      },
      "outputs": [],
      "source": [
        "## Load model\n",
        "\n",
        "# Specify bucket and model name\n",
        "bucket_name = 'gee_irrigation_detection'\n",
        "model_name = 'Nigeria_transformer' #'catboost_trained_2021_Nigeria'\n",
        "model_uri = f'saved_models/{model_name}'\n",
        "region = 'Nigeria29'\n",
        "\n",
        "# Load in model\n",
        "if \"transformer\" in model_name:\n",
        "    # model = tf.keras.models.load_model(f'gs://{bucket_name}/{model_uri}')\n",
        "    model = tf.keras.models.load_model(f'/content/{model_name}')\n",
        "elif \"catboost\" in model_name:\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    blob = storage_client.bucket(bucket_name).blob(model_uri).download_as_bytes()\n",
        "    model = CatBoostClassifier()\n",
        "    model.load_model(blob = blob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_unvIBeEWKk"
      },
      "outputs": [],
      "source": [
        "# Load raw image filenames\n",
        "\n",
        "# Initialize client and find folders in bucket\n",
        "# storage_client = storage.Client()\n",
        "storage_client = storage.Client(credentials=credentials)\n",
        "blobs = storage_client.list_blobs(bucket_name,\n",
        "                        prefix=f'smoothed_imagery/imagery_for_inference/{region}')\n",
        "\n",
        "# Can change this line if you want to take a subset of images\n",
        "cleaned_images = [blob.name for blob in blobs if '.tif' in blob.name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3pkzEMwCSCM"
      },
      "outputs": [],
      "source": [
        "## Define function for finding irrigible pixels\n",
        "\n",
        "def find_irrigible_px(smoothed_ts):\n",
        "\n",
        "    # Find 10th and 90th percentile EVI\n",
        "    min_evi = np.percentile(smoothed_ts, q=10, axis=1) + np.finfo(float).eps\n",
        "    max_evi = np.percentile(smoothed_ts, q=90, axis=1)\n",
        "\n",
        "    # Compute 90:10 percentile EVI ratio\n",
        "    evi_ratio_boolean = ((max_evi / min_evi) >= 2)\n",
        "\n",
        "    # Determine the rows that satisfy the max/min thresholds\n",
        "    min_evi_boolean = (min_evi <= 0.2)\n",
        "    max_evi_boolean = (max_evi >= 0.2)\n",
        "\n",
        "    # Extract dry season values\n",
        "    dry_season_start_ix = 1\n",
        "    dry_season_end_ix = 36\n",
        "    dry_season_evi = smoothed_ts[:, dry_season_start_ix:dry_season_end_ix]\n",
        "\n",
        "    # Compute dry season max EVI\n",
        "    dry_season_max_evi = np.max(dry_season_evi, axis=-1)\n",
        "\n",
        "    # Determine the rows that satisfy the dry season max EVI requirement\n",
        "    valid_dry_season = (dry_season_max_evi >= 0.2)\n",
        "\n",
        "    # Stack filters\n",
        "    out_image = np.stack((min_evi_boolean,\n",
        "                          max_evi_boolean,\n",
        "                          evi_ratio_boolean,\n",
        "                          valid_dry_season),\n",
        "                         axis=-1)\n",
        "\n",
        "    # Find pixels that satisfy all filters\n",
        "    valid_px = np.all(out_image, axis=-1)\n",
        "\n",
        "    return valid_px\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xZaa_AKCjJ7"
      },
      "outputs": [],
      "source": [
        "## Make model predictions and save locally\n",
        "import os\n",
        "\n",
        "# Define out directory\n",
        "out_dir = f'model_predictions/{model_name}/{region}'\n",
        "\n",
        "# Iterate through S2 imagery\n",
        "for image in cleaned_images:\n",
        "    image_uri = f'gs://{bucket_name}/{image}'\n",
        "    print(f'Processing and predicting over image: {image_uri}')\n",
        "    with rasterio.open(image_uri, 'r', driver='GTiff') as src:\n",
        "\n",
        "        # Load profile and compute total number of windowed reads\n",
        "        profile = src.profile\n",
        "        # total_windows = np.ceil(profile['width']/profile['blockxsize']) * \\\n",
        "        #                 np.ceil(profile['height']/profile['blockysize'])\n",
        "\n",
        "        # Define outfile name and profile\n",
        "        out_profile = src.meta.copy()\n",
        "        out_profile['dtype'] = rasterio.uint8\n",
        "        out_profile['count'] = 1\n",
        "\n",
        "        # Create outdirectory if it doesnt exist\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        out_name = f'{out_dir}/{image.split(\"/\")[-1]}'\n",
        "\n",
        "        # Open outfile\n",
        "        with rasterio.open(out_name, 'w+', **out_profile) as dest:\n",
        "\n",
        "            # Iterate through windowed reads\n",
        "            for ji, window in tqdm(src.block_windows(1)): #, total=total_windows):\n",
        "                image_window = src.read(window=window)\n",
        "\n",
        "                imagery_stack = image_window.transpose(1,2,0)\n",
        "\n",
        "                # Reshape and convert to DF\n",
        "                imagery_stack = imagery_stack.reshape(imagery_stack.shape[0]*\\\n",
        "                                            imagery_stack.shape[1],\n",
        "                                            imagery_stack.shape[2])\n",
        "\n",
        "                # Smooth timeseries -- If pulling from\n",
        "                # gs://gee_irrigation_detection/smoothed_imagery/imagery_for_inference\n",
        "                # imagery is already smoothed + interp. If not, will need to change\n",
        "                # next line.\n",
        "                smoothed_ts = imagery_stack\n",
        "\n",
        "                # Find valid px\n",
        "                valid_px = find_irrigible_px(smoothed_ts).astype(bool)\n",
        "\n",
        "                # Take valid_pixels\n",
        "                valid_ts = smoothed_ts[valid_px, :]\n",
        "\n",
        "\n",
        "                # Normalize\n",
        "                valid_ts =  (valid_ts - 0.2555) / 0.16886\n",
        "\n",
        "                # Loop for deep learning / transformer models\n",
        "                if 'transformer' in model_name:\n",
        "                    # Convert to up as tf.data.Dataset\n",
        "                    ds = tf.data.Dataset.from_tensor_slices(valid_ts).batch(512)\n",
        "\n",
        "                    # Create list to hold predictions\n",
        "                    predictions_list = []\n",
        "\n",
        "                    # Make predictions\n",
        "                    for ix, features in ds.enumerate():\n",
        "                        predictions = model(features, training=False)\n",
        "                        predictions = predictions[:, 1]\n",
        "                        predictions_list.extend(predictions.numpy())\n",
        "\n",
        "                    predictions_array = np.array(predictions_list)\n",
        "\n",
        "                # Loop for catboost model\n",
        "                elif 'catboost' in model_name:\n",
        "                    predictions_array = model.predict(valid_ts)\n",
        "\n",
        "                # Create output array for predictions, fill with predictions\n",
        "                prediction_output = np.zeros((len(smoothed_ts),))\n",
        "                prediction_array = (predictions_array >= 0.5).astype(int)\n",
        "                prediction_output[np.argwhere(valid_px)[:,0]] = predictions_array\n",
        "\n",
        "                prediction_output = prediction_output.reshape(1, image_window.shape[1],\n",
        "                                                              image_window.shape[2])\n",
        "\n",
        "                ## Write out\n",
        "                dest.write(prediction_output.astype(rasterio.uint8),\n",
        "                           window=window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftHcMN7xevUF"
      },
      "outputs": [],
      "source": [
        "## Export to GCP\n",
        "\n",
        "# Define export function\n",
        "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    # storage_client = storage.Client()\n",
        "    storage_client = storage.Client(credentials=credentials)\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print('File {} uploaded to {}.'.format(\n",
        "        source_file_name,\n",
        "        destination_blob_name))\n",
        "\n",
        "files_to_export = glob(f\"{out_dir}/*.tif\")\n",
        "for file_name in files_to_export:\n",
        "    upload_blob(bucket_name, file_name, file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f774aqiD05i-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}